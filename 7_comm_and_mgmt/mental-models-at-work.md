# 🧠 Mental Models for Data Science Excellence

This document defines the core mental models I actively use in my work as a data scientist. These models shape how I think, solve problems, design experiments, communicate results, and grow in my role. It draws from leading perspectives in data science thinking and is tailored for strategic work in product, marketing, and experimentation.

---

## 🧭 Systems Thinking

> “If you’re not thinking in systems, you’re not really thinking.”

- Zoom out and map how data, actions, and metrics connect across departments.
- Identify leverage points—where small input changes can drive large systemic effects.
- Use feedback loop analysis (reinforcing or balancing) to understand delayed impacts.

---

## 🔬 First Principles Thinking

- Break down complex problems into fundamental truths.
- Avoid relying on analogy or past experience—rebuild understanding from the ground up.
- Useful for creating novel solutions, simplifying modeling assumptions, and debugging.

---

## 🔁 Inversion

- Ask: “What would completely break this project?” or “What would guarantee failure?”
- Helps uncover blind spots, prevent wishful thinking, and build robust analysis plans.

---

## 🔍 Garbage In, Garbage Out (GIGO)

- If your data is biased, incomplete, or misunderstood—so are your insights.
- Start with data profiling, validation, and assumptions-checking before diving into modeling or dashboards.

---

## 📊 Law of Large Numbers

- The larger the sample, the closer estimates get to true values.
- Avoid early decisions on small datasets; embrace patient accumulation of evidence.

---

## 🎯 Pareto Principle (80/20 Rule)

- 80% of value often comes from 20% of variables.
- Focus on high-impact features, customer segments, or marketing levers before refining less important parts.

---

## ✂️ Occam’s Razor

- Choose the simplest explanation or model that fits the data.
- Simpler models are easier to debug, explain, and deploy.

---

## ⚖️ Bias–Variance Tradeoff

- Low bias = flexible models, but can overfit.
- Low variance = stable models, but can underfit.
- Your job is to balance them based on use case, signal-to-noise ratio, and business tolerance for error.

---

## 📉 Simpson’s Paradox

- A trend may appear in different groups but disappear or reverse when groups are combined.
- Always check for confounding variables and stratified results.

---

## 📐 Confirmation Bias

- We tend to interpret data to support our existing beliefs.
- Actively test the opposite of what you expect.
- Encourage disconfirming evidence in team reviews and stakeholder discussions.

  ### Ikea Effect:
    - People are partial to or place more value on things they build or partially build.

---

## 📏 P-Hacking Awareness

- Resist the temptation to test, slice, and re-test until something looks significant.
- Predefine hypotheses, keep an experiment log, and understand the cost of multiple comparisons.

---

## 📈 Model Thinking

- All models are wrong, but some are useful.
- Understand the limitations, assumptions, and purpose of every model used.
- Don’t treat outputs as truth—use them as decision aids.

---

## 🗺️ Concept Mapping

- Sketch out how different ideas, inputs, and outcomes are connected.
- Helps clarify thinking when scoping ambiguous projects or stakeholder requests.

---

## 🎩 Six Thinking Hats

- Use different thinking modes deliberately: logical, emotional, critical, optimistic, creative, and process.
- Great for team discussions, stakeholder alignment, and idea evaluation.

---

## 🧊 Iceberg Model of Behavior

- What you observe (metrics, customer behavior) is the tip.
- Below are patterns, systems, and mental models influencing behavior.
- Aim to understand **why**, not just **what**.

---

## 🧪 Experimentation and Counterfactual Thinking

- Treat your work like a scientist: isolate variables, define control groups, look for uplift.
- Always ask: what would have happened otherwise?
- Use causal inference frameworks when A/B testing is not possible.


---

## 🧠 Mental Model Stack for Daily Use

| Situation                           | Mental Models to Apply                              |
|------------------------------------|------------------------------------------------------|
| Scoping a new problem              | First Principles, Concept Mapping, Inversion        |
| Analyzing a data anomaly           | Simpson’s Paradox, Systems Thinking                 |
| Designing an experiment            | Causal Thinking, Bias–Variance, P-Hacking Awareness |
| Communicating to stakeholders      | Model Thinking, Six Hats, GIGO                      |
| Prioritizing features or segments  | Pareto Principle, Law of Large Numbers              |
| Reviewing model performance        | Occam’s Razor, Bias–Variance, Confirmation Bias     |

---

## 📅 Weekly Reflection Practice

Every Friday, ask yourself:
- What mental models did I *actively* use this week?
- Where did I react out of habit instead of thinking deliberately?
- What model would have helped me handle a tough moment better?
- What did I overcomplicate that Occam’s Razor would simplify?

---

## 📚 Sources & Further Reading

- [12 Mental Models for Data Science – Chanin Nantasenamat](https://medium.com/data-science/12-mental-models-for-data-science-f2e2133d85ea)
- [Importance of Mental Models for Data Scientists – Prdeepak Babu](https://medium.com/@prdeepak.babu/importance-of-mental-models-for-data-scientists-ml-ai-practitioners-43c4b88b4871)
- [Mental Models in Data Science – AlgoTrading101](https://algotrading101.com/learn/data-science-mental-models/)
- [Trusted Mental Models for Smarter Data Scientists – Towards Data Science](https://towardsdatascience.com/these-trusted-mental-models-will-make-you-a-more-intelligent-data-scientist-immediately-9c35fe62a31e/)

---

*This is a living document. I revisit and evolve this as I grow.*

